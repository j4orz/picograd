```
                                                                            ,,  
  mm                                                                      `7MM  
  MM                                                                        MM  
mmMMmm .gP"Ya   .gP"Ya `7MMpMMMb.`7M'   `MF'.P"Ybmmm `7Mb,od8 ,6"Yb.   ,M""bMM  
  MM  ,M'   Yb ,M'   Yb  MM    MM  VA   ,V :MI  I8     MM' "'8)   MM ,AP    MM  
  MM  8M"""""" 8M""""""  MM    MM   VA ,V   WmmmP"     MM     ,pm9MM 8MI    MM  
  MM  YM.    , YM.    ,  MM    MM    VVV   8M          MM    8M   MM `Mb    MM  
  `Mbmo`Mbmmd'  `Mbmmd'.JMML  JMML.  ,V     YMMMMMb  .JMML.  `Moo9^Yo.`Wbmd"MML.
                                    ,V     6'     dP                            
                                 OOb"      Ybmmmd'                              
```

*a teaching deep learning framework: the bridge from [micrograd](https://github.com/karpathy/micrograd) to [tinygrad](https://github.com/tinygrad/tinygrad)*

Take a whirlwind tour with the [SITP lectures and textbook](https://j4orz.ai/sitp/)
and build your own deep learning framework from scratch (a *pedagogically-omakase'd* tinygrad fork, sharing 90% of abstractions)
in order to run training and inference for [nanogpt](https://github.com/karpathy/nanoGPT) and [nanochat](https://github.com/karpathy/nanochat/) (built in [LLM101n](https://github.com/karpathy/LLM101n)).